{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20250052-4997-4552-a77c-3cbc0b84a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/mnt/edisk/dataset/unimodel_calibrate'\n",
    "model_path = 'base.onnx'\n",
    "qmodel_path = 'base.quantized.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd9c074-0fe8-4fe4-a597-643dbaf9284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.ao.quantization.observer import HistogramObserver, PerChannelMinMaxObserver\n",
    "from torch.ao.quantization.fake_quantize import FakeQuantizeBase, FakeQuantize\n",
    "\n",
    "from onnxutils.quantization import symbolic_trace, ModuleQuantizer, compute_metric, mse_kernel, cosine_kernel, snr_kernel\n",
    "\n",
    "from onnxutils.common import DatasetUtils\n",
    "from onnxutils.onnx import OnnxModel\n",
    "from onnxutils.onnx2torch import convert, normalize_module_name\n",
    "from onnxutils.onnx2torch.scatter_nd import TorchScatterNd\n",
    "from onnxutils.onnx2torch.binary_math_operations import TorchBinaryOp\n",
    "\n",
    "from unimodel_pipeline import UnimodelDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd76a4-b50c-49da-80aa-feac22f91111",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9cb5c1d-fa43-4465-b005-85357c5c1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = OnnxModel.from_file(model_path)\n",
    "with onnx_model.session() as sess:\n",
    "    for node in onnx_model.proto().graph.node:\n",
    "        if node.name == '':\n",
    "            node.name = sess.unique_name()\n",
    "onnx_model.topological_sort()\n",
    "torch_model = convert(onnx_model)\n",
    "\n",
    "dataset = UnimodelDataset(dataset_path, torch_model.onnx_mapping.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b286856e-abb0-44ea-9b82-410f6d978ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('backbone/stage1/conv/Conv', {'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}})\n",
      "('backbone/stage1/act/Relu', {'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}})\n",
      "('backbone/stage2/stage2/0/conv/Conv', {'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}})\n",
      "('backbone/stage2/stage2/0/act/Relu', {'activation': <function shared_fq.<locals>.wrapper at 0x71f8f6168430>})\n",
      "('backbone/stage2/stage2/1/conv/conv/0/conv/Conv', {'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}})\n",
      "('backbone/stage2/stage2/1/conv/conv/0/act/Relu', {'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}})\n",
      "('backbone/stage2/stage2/1/conv/conv/1/conv/Conv', {'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}})\n",
      "('backbone/stage2/stage2/1/conv/conv/1/act/Relu', {'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}})\n",
      "('backbone/stage2/stage2/1/conv/conv/2/conv/Conv', {'activation': <function shared_fq.<locals>.wrapper at 0x71f8f6168430>, 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}})\n",
      "('backbone/stage2/stage2/1/Add', {'activation': <function shared_fq.<locals>.wrapper at 0x71f8f6168430>})\n",
      "('backbone/stage2/stage2/1/relu/Relu', {'activation': <function shared_fq.<locals>.wrapper at 0x71f9e93d5e10>})\n",
      "('backbone/stage2/stage2/2/conv/conv/0/conv/Conv', {'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}})\n",
      "('backbone/stage2/stage2/2/conv/conv/0/act/Relu', {'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}})\n",
      "('backbone/stage2/stage2/2/conv/conv/1/conv/Conv', {'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}})\n",
      "('backbone/stage2/stage2/2/conv/conv/1/act/Relu', {'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}})\n",
      "('backbone/stage2/stage2/2/conv/conv/2/conv/Conv', {'activation': <function shared_fq.<locals>.wrapper at 0x71f9e93d5e10>, 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}})\n",
      "('backbone/stage2/stage2/2/Add', {'activation': <function shared_fq.<locals>.wrapper at 0x71f9e93d5e10>})\n",
      "('backbone/stage2/stage2/2/relu/Relu', {'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}})\n",
      "{'module_name': 'backbone/stage1/conv/Conv', 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}}\n",
      "{'module_name': 'backbone/stage1/act/Relu', 'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/0/conv/Conv', 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/0/act/Relu', 'activation': <function shared_fq.<locals>.wrapper at 0x71f8f6168430>}\n",
      "{'module_name': 'backbone/stage2/stage2/1/conv/conv/0/conv/Conv', 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/1/conv/conv/0/act/Relu', 'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/1/conv/conv/1/conv/Conv', 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/1/conv/conv/1/act/Relu', 'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/1/conv/conv/2/conv/Conv', 'activation': <function shared_fq.<locals>.wrapper at 0x71f8f6168430>, 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/1/Add', 'activation': <function shared_fq.<locals>.wrapper at 0x71f8f6168430>}\n",
      "{'module_name': 'backbone/stage2/stage2/1/relu/Relu', 'activation': <function shared_fq.<locals>.wrapper at 0x71f9e93d5e10>}\n",
      "{'module_name': 'backbone/stage2/stage2/2/conv/conv/0/conv/Conv', 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/2/conv/conv/0/act/Relu', 'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/2/conv/conv/1/conv/Conv', 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/2/conv/conv/1/act/Relu', 'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/2/conv/conv/2/conv/Conv', 'activation': <function shared_fq.<locals>.wrapper at 0x71f9e93d5e10>, 'weight': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>){}}\n",
      "{'module_name': 'backbone/stage2/stage2/2/Add', 'activation': <function shared_fq.<locals>.wrapper at 0x71f9e93d5e10>}\n",
      "{'module_name': 'backbone/stage2/stage2/2/relu/Relu', 'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}}\n",
      "{'name': 'imgs', 'activation': functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.ao.quantization.observer.HistogramObserver'>){}}\n"
     ]
    }
   ],
   "source": [
    "def shared_fq(cls):\n",
    "    fq = cls()\n",
    "    def wrapper():\n",
    "        return fq\n",
    "    return wrapper\n",
    "\n",
    "qconfig_mappings = {}\n",
    "for node in onnx_model.nodes():\n",
    "    if node.op_type() == 'Conv':\n",
    "        qconfig_mappings[normalize_module_name(node.name())] = {\n",
    "            'activation': FakeQuantize.with_args(observer=HistogramObserver),\n",
    "            'weight': FakeQuantize.with_args(observer=PerChannelMinMaxObserver),\n",
    "        }\n",
    "    elif node.op_type() == 'Relu':\n",
    "        qconfig_mappings[normalize_module_name(node.name())] = {\n",
    "            'activation': FakeQuantize.with_args(observer=HistogramObserver)\n",
    "        }\n",
    "        maybe_conv_node = onnx_model.get_node_by_output(node.inputs()[0])\n",
    "        if maybe_conv_node.op_type() == 'Conv':\n",
    "            qconfig_mappings[normalize_module_name(maybe_conv_node.name())].pop('activation')\n",
    "    elif node.op_type() == 'Add':\n",
    "        fq_cls = shared_fq(FakeQuantize.with_args(observer=HistogramObserver))\n",
    "        qconfig_mappings[normalize_module_name(node.name())] = {\n",
    "            'activation': fq_cls\n",
    "        }\n",
    "        for input_name in node.inputs():\n",
    "            maybe_node = onnx_model.get_node_by_output(input_name)\n",
    "            if normalize_module_name(maybe_node.name()) in qconfig_mappings:\n",
    "                qconfig_mappings[normalize_module_name(maybe_node.name())]['activation'] = fq_cls\n",
    "\n",
    "for item in qconfig_mappings.items():\n",
    "    print(item)\n",
    "\n",
    "qconfigs = [\n",
    "    {'module_name': name} | qconfig\n",
    "    for name, qconfig in qconfig_mappings.items()\n",
    "] + [{'name': 'imgs', 'activation': FakeQuantize.with_args(observer=HistogramObserver)}]\n",
    "for item in qconfigs:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5038f8-70e0-4c72-9dea-6d83a7d321d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, imgs):\n",
      "        # No stacktrace found for following nodes\n",
      "        fq0 = self.fq0(imgs);  imgs = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage1_conv_conv = getattr(self, \"backbone/stage1/conv/Conv\")(fq0);  fq0 = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage1_act_relu = getattr(self, \"backbone/stage1/act/Relu\")(backbone_stage1_conv_conv);  backbone_stage1_conv_conv = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq1 = self.fq1(backbone_stage1_act_relu);  backbone_stage1_act_relu = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_0_conv_conv = getattr(self, \"backbone/stage2/stage2/0/conv/Conv\")(fq1);  fq1 = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_0_act_relu = getattr(self, \"backbone/stage2/stage2/0/act/Relu\")(backbone_stage2_stage2_0_conv_conv);  backbone_stage2_stage2_0_conv_conv = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq2 = self.fq2(backbone_stage2_stage2_0_act_relu);  backbone_stage2_stage2_0_act_relu = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_1_conv_conv_0_conv_conv = getattr(self, \"backbone/stage2/stage2/1/conv/conv/0/conv/Conv\")(fq2)\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_1_conv_conv_0_act_relu = getattr(self, \"backbone/stage2/stage2/1/conv/conv/0/act/Relu\")(backbone_stage2_stage2_1_conv_conv_0_conv_conv);  backbone_stage2_stage2_1_conv_conv_0_conv_conv = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq3 = self.fq3(backbone_stage2_stage2_1_conv_conv_0_act_relu);  backbone_stage2_stage2_1_conv_conv_0_act_relu = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_1_conv_conv_1_conv_conv = getattr(self, \"backbone/stage2/stage2/1/conv/conv/1/conv/Conv\")(fq3);  fq3 = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_1_conv_conv_1_act_relu = getattr(self, \"backbone/stage2/stage2/1/conv/conv/1/act/Relu\")(backbone_stage2_stage2_1_conv_conv_1_conv_conv);  backbone_stage2_stage2_1_conv_conv_1_conv_conv = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq4 = self.fq4(backbone_stage2_stage2_1_conv_conv_1_act_relu);  backbone_stage2_stage2_1_conv_conv_1_act_relu = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_1_conv_conv_2_conv_conv = getattr(self, \"backbone/stage2/stage2/1/conv/conv/2/conv/Conv\")(fq4);  fq4 = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq5 = self.fq5(backbone_stage2_stage2_1_conv_conv_2_conv_conv);  backbone_stage2_stage2_1_conv_conv_2_conv_conv = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_1_add = getattr(self, \"backbone/stage2/stage2/1/Add\")(fq5, fq2);  fq5 = fq2 = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq6 = self.fq6(backbone_stage2_stage2_1_add);  backbone_stage2_stage2_1_add = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_1_relu_relu = getattr(self, \"backbone/stage2/stage2/1/relu/Relu\")(fq6);  fq6 = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq7 = self.fq7(backbone_stage2_stage2_1_relu_relu);  backbone_stage2_stage2_1_relu_relu = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_2_conv_conv_0_conv_conv = getattr(self, \"backbone/stage2/stage2/2/conv/conv/0/conv/Conv\")(fq7)\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_2_conv_conv_0_act_relu = getattr(self, \"backbone/stage2/stage2/2/conv/conv/0/act/Relu\")(backbone_stage2_stage2_2_conv_conv_0_conv_conv);  backbone_stage2_stage2_2_conv_conv_0_conv_conv = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq8 = self.fq8(backbone_stage2_stage2_2_conv_conv_0_act_relu);  backbone_stage2_stage2_2_conv_conv_0_act_relu = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_2_conv_conv_1_conv_conv = getattr(self, \"backbone/stage2/stage2/2/conv/conv/1/conv/Conv\")(fq8);  fq8 = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_2_conv_conv_1_act_relu = getattr(self, \"backbone/stage2/stage2/2/conv/conv/1/act/Relu\")(backbone_stage2_stage2_2_conv_conv_1_conv_conv);  backbone_stage2_stage2_2_conv_conv_1_conv_conv = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq9 = self.fq9(backbone_stage2_stage2_2_conv_conv_1_act_relu);  backbone_stage2_stage2_2_conv_conv_1_act_relu = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_2_conv_conv_2_conv_conv = getattr(self, \"backbone/stage2/stage2/2/conv/conv/2/conv/Conv\")(fq9);  fq9 = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq10 = self.fq10(backbone_stage2_stage2_2_conv_conv_2_conv_conv);  backbone_stage2_stage2_2_conv_conv_2_conv_conv = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_2_add = getattr(self, \"backbone/stage2/stage2/2/Add\")(fq10, fq7);  fq10 = fq7 = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq11 = self.fq11(backbone_stage2_stage2_2_add);  backbone_stage2_stage2_2_add = None\n",
      "        \n",
      "         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = ''.join(CapturedTraceback.extract().format())\n",
      "        backbone_stage2_stage2_2_relu_relu = getattr(self, \"backbone/stage2/stage2/2/relu/Relu\")(fq11);  fq11 = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        fq12 = self.fq12(backbone_stage2_stage2_2_relu_relu);  backbone_stage2_stage2_2_relu_relu = None\n",
      "        return fq12\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class GraphModule(torch.nn.Module):\\n    def forward(self, imgs):\\n        # No stacktrace found for following nodes\\n        fq0 = self.fq0(imgs);  imgs = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage1_conv_conv = getattr(self, \"backbone/stage1/conv/Conv\")(fq0);  fq0 = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage1_act_relu = getattr(self, \"backbone/stage1/act/Relu\")(backbone_stage1_conv_conv);  backbone_stage1_conv_conv = None\\n        \\n        # No stacktrace found for following nodes\\n        fq1 = self.fq1(backbone_stage1_act_relu);  backbone_stage1_act_relu = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_0_conv_conv = getattr(self, \"backbone/stage2/stage2/0/conv/Conv\")(fq1);  fq1 = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_0_act_relu = getattr(self, \"backbone/stage2/stage2/0/act/Relu\")(backbone_stage2_stage2_0_conv_conv);  backbone_stage2_stage2_0_conv_conv = None\\n        \\n        # No stacktrace found for following nodes\\n        fq2 = self.fq2(backbone_stage2_stage2_0_act_relu);  backbone_stage2_stage2_0_act_relu = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_1_conv_conv_0_conv_conv = getattr(self, \"backbone/stage2/stage2/1/conv/conv/0/conv/Conv\")(fq2)\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_1_conv_conv_0_act_relu = getattr(self, \"backbone/stage2/stage2/1/conv/conv/0/act/Relu\")(backbone_stage2_stage2_1_conv_conv_0_conv_conv);  backbone_stage2_stage2_1_conv_conv_0_conv_conv = None\\n        \\n        # No stacktrace found for following nodes\\n        fq3 = self.fq3(backbone_stage2_stage2_1_conv_conv_0_act_relu);  backbone_stage2_stage2_1_conv_conv_0_act_relu = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_1_conv_conv_1_conv_conv = getattr(self, \"backbone/stage2/stage2/1/conv/conv/1/conv/Conv\")(fq3);  fq3 = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_1_conv_conv_1_act_relu = getattr(self, \"backbone/stage2/stage2/1/conv/conv/1/act/Relu\")(backbone_stage2_stage2_1_conv_conv_1_conv_conv);  backbone_stage2_stage2_1_conv_conv_1_conv_conv = None\\n        \\n        # No stacktrace found for following nodes\\n        fq4 = self.fq4(backbone_stage2_stage2_1_conv_conv_1_act_relu);  backbone_stage2_stage2_1_conv_conv_1_act_relu = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_1_conv_conv_2_conv_conv = getattr(self, \"backbone/stage2/stage2/1/conv/conv/2/conv/Conv\")(fq4);  fq4 = None\\n        \\n        # No stacktrace found for following nodes\\n        fq5 = self.fq5(backbone_stage2_stage2_1_conv_conv_2_conv_conv);  backbone_stage2_stage2_1_conv_conv_2_conv_conv = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_1_add = getattr(self, \"backbone/stage2/stage2/1/Add\")(fq5, fq2);  fq5 = fq2 = None\\n        \\n        # No stacktrace found for following nodes\\n        fq6 = self.fq6(backbone_stage2_stage2_1_add);  backbone_stage2_stage2_1_add = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_1_relu_relu = getattr(self, \"backbone/stage2/stage2/1/relu/Relu\")(fq6);  fq6 = None\\n        \\n        # No stacktrace found for following nodes\\n        fq7 = self.fq7(backbone_stage2_stage2_1_relu_relu);  backbone_stage2_stage2_1_relu_relu = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_2_conv_conv_0_conv_conv = getattr(self, \"backbone/stage2/stage2/2/conv/conv/0/conv/Conv\")(fq7)\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_2_conv_conv_0_act_relu = getattr(self, \"backbone/stage2/stage2/2/conv/conv/0/act/Relu\")(backbone_stage2_stage2_2_conv_conv_0_conv_conv);  backbone_stage2_stage2_2_conv_conv_0_conv_conv = None\\n        \\n        # No stacktrace found for following nodes\\n        fq8 = self.fq8(backbone_stage2_stage2_2_conv_conv_0_act_relu);  backbone_stage2_stage2_2_conv_conv_0_act_relu = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_2_conv_conv_1_conv_conv = getattr(self, \"backbone/stage2/stage2/2/conv/conv/1/conv/Conv\")(fq8);  fq8 = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_2_conv_conv_1_act_relu = getattr(self, \"backbone/stage2/stage2/2/conv/conv/1/act/Relu\")(backbone_stage2_stage2_2_conv_conv_1_conv_conv);  backbone_stage2_stage2_2_conv_conv_1_conv_conv = None\\n        \\n        # No stacktrace found for following nodes\\n        fq9 = self.fq9(backbone_stage2_stage2_2_conv_conv_1_act_relu);  backbone_stage2_stage2_2_conv_conv_1_act_relu = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_2_conv_conv_2_conv_conv = getattr(self, \"backbone/stage2/stage2/2/conv/conv/2/conv/Conv\")(fq9);  fq9 = None\\n        \\n        # No stacktrace found for following nodes\\n        fq10 = self.fq10(backbone_stage2_stage2_2_conv_conv_2_conv_conv);  backbone_stage2_stage2_2_conv_conv_2_conv_conv = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_2_add = getattr(self, \"backbone/stage2/stage2/2/Add\")(fq10, fq7);  fq10 = fq7 = None\\n        \\n        # No stacktrace found for following nodes\\n        fq11 = self.fq11(backbone_stage2_stage2_2_add);  backbone_stage2_stage2_2_add = None\\n        \\n         # File: /opt/miniconda3/lib/python3.10/site-packages/torch/fx/proxy.py:219 in create_proxy, code: proxy.node.stack_trace = \\'\\'.join(CapturedTraceback.extract().format())\\n        backbone_stage2_stage2_2_relu_relu = getattr(self, \"backbone/stage2/stage2/2/relu/Relu\")(fq11);  fq11 = None\\n        \\n        # No stacktrace found for following nodes\\n        fq12 = self.fq12(backbone_stage2_stage2_2_relu_relu);  backbone_stage2_stage2_2_relu_relu = None\\n        return fq12\\n        '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_model = pickle.loads(pickle.dumps(torch_model))\n",
    "graph_model = symbolic_trace(graph_model, skipped_module_classes=[TorchScatterNd, TorchBinaryOp])\n",
    "\n",
    "quantizer = ModuleQuantizer()\n",
    "graph_model = quantizer.quantize(graph_model, qconfigs)\n",
    "\n",
    "graph_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfa59ab-9d20-47fb-a9a7-5747cbf77667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 256/256 [01:49<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# calibration\n",
    "for m in graph_model.modules():\n",
    "    if isinstance(m, FakeQuantizeBase):\n",
    "        m.disable_fake_quant()\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    DatasetUtils.take_front(\n",
    "        DatasetUtils.transform(\n",
    "            dataset,\n",
    "            lambda items: tuple(x.to('cuda') for x in items)\n",
    "        ),\n",
    "        256\n",
    "    ),\n",
    "    batch_size=None\n",
    ")\n",
    "graph_model.eval().to('cuda')\n",
    "for data in tqdm(dataloader):\n",
    "    graph_model(*data)\n",
    "\n",
    "for m in graph_model.modules():\n",
    "    if isinstance(m, FakeQuantizeBase):\n",
    "        m.enable_fake_quant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724cba1-e430-4af7-af22-3f5addcf9250",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "011d45e8-160d-482a-b37b-5d4eb4fa76eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_0 0.9939883947372437\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(\n",
    "    DatasetUtils.take_front(\n",
    "        DatasetUtils.transform(\n",
    "            dataset,\n",
    "            lambda items: tuple(x.to('cuda') for x in items)\n",
    "        ),\n",
    "        256\n",
    "    ),\n",
    "    batch_size=None\n",
    ")\n",
    "torch_model.eval().to('cuda')\n",
    "graph_model.eval().to('cuda')\n",
    "\n",
    "for data in dataloader:\n",
    "    gt = torch_model(*data)\n",
    "    pred = graph_model(*data)\n",
    "\n",
    "    for name, metric, val0, val1 in zip(torch_model.onnx_mapping.outputs, compute_metric(gt, pred, cosine_kernel), gt, pred):\n",
    "        print(name, metric)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0074b-0a54-47ed-862e-1520fe23015d",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77288f2c-fec4-4452-b8b7-522574107f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_model = quantizer.finalize(graph_model).to('cuda')\n",
    "\n",
    "torch.onnx.export(\n",
    "    finalized_model,\n",
    "    tuple(next(iter(dataloader))),\n",
    "    qmodel_path,\n",
    "    input_names=torch_model.onnx_mapping.inputs,\n",
    "    output_names=torch_model.onnx_mapping.outputs,\n",
    ")\n",
    "# torch.onnx.export(\n",
    "#     torch_model,\n",
    "#     tuple(next(iter(dataloader))),\n",
    "#     model_path,\n",
    "#     input_names=torch_model.onnx_mapping.inputs,\n",
    "#     output_names=torch_model.onnx_mapping.outputs,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d63fb0-65da-4d24-94f5-679a90921b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
